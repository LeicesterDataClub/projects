---
title: "Romeo & Juliet"
output:
  html_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
library(tm)
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(wordcloud)
library(slam)
```


## Get data:

The `gutenberg_download` function retrieves texts from Project Gutenberg but it's good practice not to keep hitting the server, so I've downloaded the files and saved them locally.

```{r download}
#RomeoJuliet <- gutenberg_download(1513)
#RomeoJuliet <- gutenberg_download(1532)
RomeoJuliet <- read_csv("TextData/RandJText.csv")
```

## Explore

### Let's look at the scenes.

```{r}
scenes <- str_subset(RomeoJuliet$text, "Scene")
scenes
```

### Let's look at the stage directions.

We are going to be using regular expressions a lot. There's loads of information out there, but my favourite site is: https://www.rexegg.com/

```{r}
stage_directions <- str_subset(RomeoJuliet$text, "\\[")
head(stage_directions, 20)
```

### Speaker first lines

```{r}
they_said <- function(speaker){
  pattern <- paste("^", speaker, "\\.", sep = "")
  RomeoJuliet$text[str_which(RomeoJuliet$text, pattern) + 1]
}

head(they_said("Romeo"), 20)
```



### Can we detect speakers?

```{r}
speakers <- str_subset(RomeoJuliet$text, "^[A-Z]\\w+\\.$")
unique(speakers)
```

```{r}
speakers <- str_subset(RomeoJuliet$text, "^[A-Z]\\w+\\.$|^[A-Z]\\w+\\s+[A-Z]\\w+\\.$")
unique(speakers)
```

## Question - Are Romeo & Juliet compatible?

Maybe they are if their speech is similar.

## Restructuring the data

```{r}

RJ_processed <- 
  RomeoJuliet %>% 
  select(-gutenberg_id) %>%                                                                # Remove the ID column
  filter(row_number() >= str_which(RomeoJuliet$text, "^ACT")[1]) %>%                       # Remove all the lines before Act 1
  filter(!str_detect(text, "^ACT")) %>%                                                    # Remove all the lines starting with ACT
  filter(!str_detect(text, "^Scene")) %>%                                                  # Remove all the lines starting with Scene
  filter(!str_detect(text, "^\\[.+\\]")) %>%                                               # Remove all the lines that look like [...]
  filter(text != "") %>%                                                                   # Remove all the blank lines
  mutate(Change = str_detect(text, "^[A-Z]\\w+\\.$|^[A-Z]\\w+\\s+[A-Z]\\w+\\.$" )) %>%     # Add a column to show when there is a new speaker
  mutate(Speaker = "")                                                                     # Create a column for the Speaker's name
```

```{r}
# Add the speaker's name to each column
speaker <- ""
for (i in seq_along(RJ_processed$Change)){
 if (RJ_processed$Change[i]){
   speaker <- RJ_processed$text[i]
 }
 else {
   RJ_processed$Speaker[i] <-  speaker
 }
}

RJ_processed <- 
  RJ_processed %>% 
  select(-Change) %>% 
  filter(Speaker != "")
```

RJ_processed is our key data structure, we have the lines in one column and the speaker in another:

```{r}
head(RJ_processed,20)
```



### Who has most lines?

```{r}
RJ_lines <- 
RJ_processed %>% 
  group_by(Speaker) %>% 
  summarise(Lines = n()) %>% 
  arrange(desc(Lines))
RJ_lines

RJ_top_speakers <- 
  RJ_lines %>% 
  filter(Lines > 100)

RJ_top_speakers <- RJ_top_speakers$Speaker
```

### Splitting into words

The reference for this next bit is: https://www.tidytextmining.com/

```{r}
RJ_tidy <- 
  RJ_processed %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words)
```

```{r}
RJ_word_counts <- 
  RJ_tidy %>% 
  group_by(Speaker, word) %>% 
  summarise(Count = n())
```

### Commonest words


```{r}
RJ_word_counts %>% 
  group_by(word) %>% 
  summarize(number = sum(Count)) %>% 
  arrange(desc(number))
```

### Word clouds

```{r}
# Romeo_words <- 
#   RJ_word_counts %>% 
#   filter(Speaker == "Romeo.") %>% 
#   arrange(desc(Count))
# 
# Juliet_words <- 
#   RJ_word_counts %>% 
#   filter(Speaker == "Juliet.") %>% 
#   arrange(desc(Count))
# 
# Merc_words <- 
#   RJ_word_counts %>% 
#   filter(Speaker == "Mercutio.") %>% 
#   arrange(desc(Count))
```

```{r}
wcloud <- function(wcounts, speaker, min_freq = 4){
  words <- filter(wcounts, Speaker == speaker)$word
  counts <- filter(wcounts, Speaker == speaker)$Count
  wordcloud(words, counts, min.freq = min_freq)
}
wcloud(RJ_word_counts, "Romeo.")
wcloud(RJ_word_counts, "Juliet.")
wcloud(RJ_word_counts, "Mercutio.")

```

Hmm. Lots of thous, thees and thys. Looks like we need a Shakesperian stop words list methinks.


## How can we measure the closeness of two speeches?


```{r}
dtm <- 
  RJ_word_counts %>% 
  filter(Speaker %in% RJ_top_speakers) %>% 
  cast_dtm(Speaker, word, Count)

```


```{r}
dtm <- dtm/sqrt(row_sums(dtm^2))
euc_dist <- tcrossapply_simple_triplet_matrix(dtm, FUN = function(x,y) sqrt(sum((x-y)^2)))
euc_dist[upper.tri(euc_dist, diag = TRUE)] <- 1
lovers <- which(euc_dist == min(euc_dist), arr.ind = TRUE)
```

This section needs a lot more explanation and work, but...

...The most compatible characters are...

<span style = "color:red; font-size:300%;">
`r rownames(euc_dist)[lovers[1]]`
</span>

and

<span style = "color:red; font-size:300%;">
`r colnames(euc_dist)[lovers[2]]`
</span>





